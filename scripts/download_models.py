"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è A100 80GB
–ó–∞–ø—É—Å–∫: python download_models.py
"""
import os
import subprocess
from pathlib import Path

# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –º–æ–¥–µ–ª–µ–π (–≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞, –Ω–∞ –æ–¥–Ω–æ–º —É—Ä–æ–≤–Ω–µ —Å–æ scripts/)
MODELS_DIR = Path(__file__).parent.parent / "models"
MODELS_DIR.mkdir(parents=True, exist_ok=True)

# –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
# –ï–î–ò–ù–ê–Ø –ú–û–î–ï–õ–¨: Qwen3-32B –¥–ª—è –≤—Å–µ—Ö –∑–∞–¥–∞—á (–∏ –æ—á–∏—Å—Ç–∫–∞ –∏ reranking)
MODELS = {
    "embedding": {
        "repo": "BAAI/bge-m3",
        "description": "BGE-M3 embedding –º–æ–¥–µ–ª—å (–ª—É—á—à–∞—è multilingual)",
        "size": "~2 GB"
    },
    "llm": {
        "repo": "unsloth/Qwen3-32B-GGUF",
        "files": ["Qwen3-32B-IQ4_NL.gguf"],  # IQ4_NL - –±—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –±–∞–ª–∞–Ω—Å–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞
        "description": "Qwen3-32B IQ4_NL (unsloth, –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∏ reranking, –±—ã—Å—Ç—Ä–æ ~35-40 —Å–µ–∫/–¥–æ–∫)",
        "size": "~20 GB"
    }
}

def check_huggingface_cli():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ huggingface-cli"""
    try:
        subprocess.run(["huggingface-cli", "--version"], check=True, capture_output=True)
        print("‚úÖ huggingface-cli —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return True
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("‚ùå huggingface-cli –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("\n–£—Å—Ç–∞–Ω–æ–≤–∏:")
        print("  pip install huggingface_hub")
        return False

def download_model(model_name, config):
    """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    print(f"\n{'='*80}")
    print(f"üì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ: {model_name}")
    print(f"   –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π: {config['repo']}")
    print(f"   –û–ø–∏—Å–∞–Ω–∏–µ: {config['description']}")
    print(f"   –†–∞–∑–º–µ—Ä: {config['size']}")
    print(f"{'='*80}\n")

    # –î–ª—è embedding –º–æ–¥–µ–ª–µ–π - —Å–∫–∞—á–∏–≤–∞–µ–º –≤–µ—Å—å —Ä–µ–ø–æ
    if model_name == "embedding":
        cmd = [
            "huggingface-cli", "download",
            config["repo"],
            "--local-dir", str(MODELS_DIR / "bge-m3")
        ]

    # –î–ª—è GGUF —Ñ–∞–π–ª–æ–≤ - —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Ñ–∞–π–ª—ã
    elif "files" in config:
        for file in config["files"]:
            cmd = [
                "huggingface-cli", "download",
                config["repo"],
                file,
                "--local-dir", str(MODELS_DIR)
            ]
            print(f"–ö–æ–º–∞–Ω–¥–∞: {' '.join(cmd)}")
            subprocess.run(cmd, check=True)
        return True

    # –î–ª—è HuggingFace –º–æ–¥–µ–ª–µ–π - –≤–µ—Å—å —Ä–µ–ø–æ
    else:
        model_dir = MODELS_DIR / config["repo"].split("/")[-1]
        cmd = [
            "huggingface-cli", "download",
            config["repo"],
            "--local-dir", str(model_dir)
        ]

    print(f"–ö–æ–º–∞–Ω–¥–∞: {' '.join(cmd)}")

    try:
        subprocess.run(cmd, check=True)
        print(f"‚úÖ {model_name} —Å–∫–∞—á–∞–Ω!")
        return True
    except subprocess.CalledProcessError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ {model_name}: {e}")
        return False

def main():
    print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                   –°–ö–ê–ß–ò–í–ê–ù–ò–ï –ú–û–î–ï–õ–ï–ô –î–õ–Ø A100 80GB                           ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ HuggingFace CLI
    if not check_huggingface_cli():
        return

    # –†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
    print("\nüìä –¢—Ä–µ–±—É–µ–º–æ–µ –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ:")
    print("   BGE-M3:              ~2 GB")
    print("   Qwen3-32B (IQ4_NL):  ~20 GB (–ï–î–ò–ù–ê–Ø –º–æ–¥–µ–ª—å –¥–ª—è –≤—Å–µ—Ö –∑–∞–¥–∞—á, –±—ã—Å—Ç—Ä–æ)")
    print("   " + "-" * 50)
    print("   –ò–¢–û–ì–û:               ~22 GB")

    confirm = input("\n‚ö†Ô∏è  –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ? (yes/no): ")
    if confirm.lower() != 'yes':
        print("–û—Ç–º–µ–Ω–µ–Ω–æ.")
        return

    # –°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª–∏
    success = []
    failed = []

    for model_name, config in MODELS.items():
        print(f"\n[{len(success)+len(failed)+1}/{len(MODELS)}] {model_name}")

        if download_model(model_name, config):
            success.append(model_name)
        else:
            failed.append(model_name)

    # –ò—Ç–æ–≥–∏
    print("\n" + "="*80)
    print("üìä –ò–¢–û–ì–ò –°–ö–ê–ß–ò–í–ê–ù–ò–Ø:")
    print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ: {len(success)}/{len(MODELS)}")
    if success:
        print(f"      {', '.join(success)}")

    if failed:
        print(f"   ‚ùå –û—à–∏–±–∫–∏: {len(failed)}/{len(MODELS)}")
        print(f"      {', '.join(failed)}")

    print("="*80)

    # –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏
    if len(success) == len(MODELS):
        print("\n‚úÖ –í–°–ï –ú–û–î–ï–õ–ò –°–ö–ê–ß–ê–ù–´!")
        print("\nüìã –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print("1. –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:")
        print("   bash full_pipeline.sh")
        print("\n–ò–ª–∏ –≤—Ä—É—á–Ω—É—é –ø–æ —à–∞–≥–∞–º:")
        print("1. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å Weaviate:")
        print("   docker-compose up -d")
        print("\n2. –°–æ–∑–¥–∞—Ç—å —á–∞–Ω–∫–∏:")
        print("   python main_pipeline.py chunk")
        print("\n3. –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–µ–¥–æ—á–∏—Å—Ç–∫—É —á–µ—Ä–µ–∑ Qwen3-32B:")
        print("   python scripts/preprocess_documents_qwen25.py")
        print("\n4. –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å embeddings:")
        print("   python main_pipeline.py build --input data/processed/chunks_cleaned.csv")
        print("\n5. –ó–∞–ø—É—Å—Ç–∏—Ç—å inference:")
        print("   python main_pipeline.py search")
    else:
        print("\n‚ö†Ô∏è  –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª–∏ –Ω–µ —Å–∫–∞—á–∞–ª–∏—Å—å. –ü—Ä–æ–≤–µ—Ä—å –æ—à–∏–±–∫–∏ –≤—ã—à–µ.")
        print("–ú–æ–∂–Ω–æ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∫–æ–º–∞–Ω–¥–æ–π: python download_models.py")

if __name__ == "__main__":
    main()
